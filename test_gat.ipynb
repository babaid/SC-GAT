{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.loader import DataLoader, NeighborLoader\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import SimpleGAT, BenchmarkGAT\n",
    "from train import train_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the SC-GAT layer?\n",
    "\n",
    "The usual for of a GAT is defined by the following equations:\n",
    "\n",
    "$$\n",
    "e_{ij} = a(\\mathbf{W}_1\\mathbf{h}_i|| \\mathbf{W}_2 \\mathbf{h_j}),\n",
    "$$\n",
    "\n",
    "where the $\\mathbf{h}_i$ are the node vectors and the $\\mathbf{W}_i$ are weight matrices. In the original implementation $\\mathbf{W}_1 = \\mathbf{W}_2 = \\mathbf{W}$.\n",
    "We then calculate the attention weights with\n",
    "\n",
    "$$\n",
    "\\alpha_{ij} = softmax(e_{ij})\n",
    "$$\n",
    "\n",
    "We call \"a\" an attentional mechanism which is usually just a plain simple single layer NN.\n",
    "\n",
    "From the first equation we have to possible directions, which is \"simplification\", which leads to GATv2Conv, where we dont concatenate, we only calculate $\\mathbf{x}_i+\\mathbf{x}_j$.\n",
    "Which is already close to the next idea. We could include $\\mathbf{x}_i-\\mathbf{x}_j$ into our attention mechanism. As mentioned in the GAT paper, the general GAT model loses every sense of structure, and every node attends over every node. So we are looking for a way to retain local and global structures, just like EdgeConv did, but with the power of attention.\n",
    "\n",
    "So the idea is to change the first equation to this:\n",
    "\n",
    "$$\n",
    "e_{ij} = a(\\mathbf{W}[\\mathbf{h}_i^T||\\mathbf{h}_j^T||\\mathbf{h}_i^T-\\mathbf{h}_j^T]^T)\n",
    "$$\n",
    "Here $||$ denotes concatenation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on Planetoid datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Planetoid(root=\"Planetoid/PubMed/\", name=\"PubMed\", split=\"full\", num_val=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = NeighborLoader(train_dataset[0], input_nodes=train_dataset[0].train_mask,\n",
    "                              num_neighbors=[50, 50, 50], shuffle=True, batch_size=64)\n",
    "val_loader =NeighborLoader(train_dataset[0], input_nodes=train_dataset[0].val_mask,\n",
    "                              num_neighbors=[50, 50], shuffle=True, batch_size=20)\n",
    "\n",
    "loaders = {\"train\": train_loader, \"val\": val_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleGAT(in_channels=500, out_channels = 3 ,heads=4, hidden_size=100).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[7581, 500], edge_index=[2, 20504], y=[7581], train_mask=[7581], val_mask=[7581], test_mask=[7581], n_id=[7581], e_id=[20504], num_sampled_nodes=[4], num_sampled_edges=[3], input_id=[64], batch_size=64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test pass trough model\n",
    "d = next(iter(train_loader))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7581, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = model(d.to(\"cuda\"))\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adadelta(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 1.08\n",
      "Epoch 0, Accuracy: 45.36%\n",
      "Epoch 5, Accuracy: 47.91%\n",
      "Epoch 10, Train Loss: 0.99\n",
      "Epoch 10, Accuracy: 67.09%\n",
      "Epoch 15, Accuracy: 71.46%\n"
     ]
    }
   ],
   "source": [
    "train_classifier(model, optim, loaders, loss_fn, 100, print_every=10, test_every=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to baseline GAT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BenchmarkGAT(in_channels=500, out_channels = 3 ,heads=4, hidden_size=100).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classifier(model, optim, loaders, loss_fn, 100, print_every=10, test_every=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
