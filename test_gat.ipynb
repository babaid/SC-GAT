{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.loader import DataLoader, NeighborLoader\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import SimpleGAT, BenchmarkGAT\n",
    "from train import train_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the SC-GAT layer?\n",
    "\n",
    "The usual for of a GAT is defined by the following equations:\n",
    "\n",
    "$$\n",
    "e_{ij} = a(\\mathbf{W}_1\\mathbf{h}_i|| \\mathbf{W}_2 \\mathbf{h_j}),\n",
    "$$\n",
    "\n",
    "where the $\\mathbf{h}_i$ are the node vectors and the $\\mathbf{W}_i$ are weight matrices. In the original implementation $\\mathbf{W}_1 = \\mathbf{W}_2 = \\mathbf{W}$.\n",
    "We then calculate the attention weights with\n",
    "\n",
    "$$\n",
    "\\alpha_{ij} = softmax(e_{ij})\n",
    "$$\n",
    "\n",
    "We call \"a\" an attentional mechanism which is usually just a plain simple single layer NN.\n",
    "\n",
    "From the first equation we have to possible directions, which is \"simplification\", which leads to GATv2Conv, where we dont concatenate, we only calculate $\\mathbf{x}_i+\\mathbf{x}_j$.\n",
    "Which is already close to the next idea. We could include $\\mathbf{x}_i-\\mathbf{x}_j$ into our attention mechanism. As mentioned in the GAT paper, the general GAT model loses every sense of structure, and every node attends over every node. So we are looking for a way to retain local and global structures, just like EdgeConv did, but with the power of attention.\n",
    "\n",
    "So the idea is to change the first equation to this:\n",
    "\n",
    "$$\n",
    "e_{ij} = a(\\mathbf{W}[\\mathbf{h}_i^T||\\mathbf{h}_j^T||\\mathbf{h}_i^T-\\mathbf{h}_j^T]^T)\n",
    "$$\n",
    "Here $||$ denotes concatenation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on Planetoid datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Planetoid(root=\"Planetoid/PubMed/\", name=\"PubMed\", split=\"full\", num_val=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = NeighborLoader(train_dataset[0], input_nodes=train_dataset[0].train_mask,\n",
    "                              num_neighbors=[50, 50, 50], shuffle=True, batch_size=64)\n",
    "val_loader =NeighborLoader(train_dataset[0], input_nodes=train_dataset[0].val_mask,\n",
    "                              num_neighbors=[50, 50], shuffle=True, batch_size=20)\n",
    "\n",
    "loaders = {\"train\": train_loader, \"val\": val_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = SimpleGAT(in_channels=500, out_channels = 3 ,heads=4, hidden_size=100).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[10754, 500], edge_index=[2, 35189], y=[10754], train_mask=[10754], val_mask=[10754], test_mask=[10754], n_id=[10754], e_id=[35189], num_sampled_nodes=[4], num_sampled_edges=[3], input_id=[64], batch_size=64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test pass trough model\n",
    "d = next(iter(train_loader))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10754, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = model1(d.to(\"cuda\"))\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adadelta(model1.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 1.08\n",
      "Epoch 0, Accuracy: 45.36%\n",
      "Epoch 5, Accuracy: 47.91%\n",
      "Epoch 10, Train Loss: 0.99\n",
      "Epoch 10, Accuracy: 67.09%\n",
      "Epoch 15, Accuracy: 71.46%\n",
      "Epoch 20, Train Loss: 0.92\n",
      "Epoch 20, Accuracy: 69.36%\n",
      "Epoch 25, Accuracy: 69.85%\n",
      "Epoch 30, Train Loss: 0.84\n",
      "Epoch 30, Accuracy: 69.82%\n",
      "Epoch 35, Accuracy: 71.38%\n",
      "Epoch 40, Train Loss: 0.76\n",
      "Epoch 40, Accuracy: 72.07%\n",
      "Epoch 45, Accuracy: 73.35%\n",
      "Epoch 50, Train Loss: 0.7\n",
      "Epoch 50, Accuracy: 74.27%\n",
      "Epoch 55, Accuracy: 74.7%\n",
      "Epoch 60, Train Loss: 0.65\n",
      "Epoch 60, Accuracy: 75.48%\n",
      "Epoch 65, Accuracy: 76.7%\n",
      "Epoch 70, Train Loss: 0.61\n",
      "Epoch 70, Accuracy: 77.57%\n",
      "Epoch 75, Accuracy: 78.17%\n",
      "Epoch 80, Train Loss: 0.57\n",
      "Epoch 80, Accuracy: 79.1%\n",
      "Epoch 85, Accuracy: 79.75%\n",
      "Epoch 90, Train Loss: 0.55\n",
      "Epoch 90, Accuracy: 81.11%\n",
      "Epoch 95, Accuracy: 81.3%\n"
     ]
    }
   ],
   "source": [
    "train_classifier(model, optim, loaders, loss_fn, 100, print_every=10, test_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"scgat.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to baseline GAT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = BenchmarkGAT(in_channels=500, out_channels = 3 ,heads=4, hidden_size=100).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adadelta(model2.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 1.09\n",
      "Epoch 0, Accuracy: 46.34%\n"
     ]
    }
   ],
   "source": [
    "train_classifier(model2, optim, loaders, loss_fn, 100, print_every=1, test_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
